{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoq5DURzS97",
        "outputId": "4ddbe878-9e35-4fc2-dc2e-2f3ae2e9c45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNYfEqG2iiyV",
        "outputId": "d41db0f7-63ab-4036-a471-95d1500fef21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.25.2)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.34.59-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (0.1.99)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.1.0)\n",
            "Collecting botocore<1.35.0,>=1.34.59 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.34.59-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2024.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.59->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.59->boto3->pytorch-transformers) (1.16.0)\n",
            "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.34.59 botocore-1.34.59 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.10.0 sacremoses-0.1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkqTCHm8l4Qp",
        "outputId": "a4929636-6d23-4f8e-aed6-c9a43ec88159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.25.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.34.59)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.1.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.59 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.34.59)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.59->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.59->boto3->pytorch-pretrained-bert) (1.16.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-pretrained-bert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotmap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M14Ujc-NlTsP",
        "outputId": "48b3cbfc-9e69-44b2-b69c-788641edf64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotmap\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: dotmap\n",
            "Successfully installed dotmap-1.3.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVLzi18Ahalw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init, Parameter\n",
        "from torch.nn import CrossEntropyLoss, BCELoss, BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "from dotmap import DotMap\n",
        "import six\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "#from file_utils import cached_path\n",
        "import logging\n",
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1keKtE29vTJB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"/content/drive/My Drive/train_chunk.csv\")\n",
        "val_df = pd.read_csv(\"/content/drive/My Drive/val_chunk.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/My Drive/test_chunk.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kxhI3ZCzY5r",
        "outputId": "2ffca9ca-d68e-4c8a-9325-8df962fd5e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPU is 1\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"Number of GPU is {}\".format(n_gpu))\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2mJg9dwiUp6"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, maxlen=None, dtype='int32',\n",
        "                  padding='pre', truncating='pre', value=0.):\n",
        "    \"\"\"Pads sequences to the same length.\n",
        "\n",
        "    This function transforms a list of\n",
        "    `num_samples` sequences (lists of integers)\n",
        "    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n",
        "    `num_timesteps` is either the `maxlen` argument if provided,\n",
        "    or the length of the longest sequence otherwise.\n",
        "\n",
        "    Sequences that are shorter than `num_timesteps`\n",
        "    are padded with `value` at the end.\n",
        "\n",
        "    Sequences longer than `num_timesteps` are truncated\n",
        "    so that they fit the desired length.\n",
        "    The position where padding or truncation happens is determined by\n",
        "    the arguments `padding` and `truncating`, respectively.\n",
        "\n",
        "    Pre-padding is the default.\n",
        "\n",
        "    # Arguments\n",
        "        sequences: List of lists, where each element is a sequence.\n",
        "        maxlen: Int, maximum length of all sequences.\n",
        "        dtype: Type of the output sequences.\n",
        "            To pad sequences with variable length strings, you can use `object`.\n",
        "        padding: String, 'pre' or 'post':\n",
        "            pad either before or after each sequence.\n",
        "        truncating: String, 'pre' or 'post':\n",
        "            remove values from sequences larger than\n",
        "            `maxlen`, either at the beginning or at the end of the sequences.\n",
        "        value: Float or String, padding value.\n",
        "\n",
        "    # Returns\n",
        "        x: Numpy array with shape `(len(sequences), maxlen)`\n",
        "\n",
        "    # Raises\n",
        "        ValueError: In case of invalid values for `truncating` or `padding`,\n",
        "            or in case of invalid shape for a `sequences` entry.\n",
        "    \"\"\"\n",
        "    if not hasattr(sequences, '__len__'):\n",
        "        raise ValueError('`sequences` must be iterable.')\n",
        "    num_samples = len(sequences)\n",
        "\n",
        "    lengths = []\n",
        "    for x in sequences:\n",
        "        try:\n",
        "            lengths.append(len(x))\n",
        "        except TypeError:\n",
        "            raise ValueError('`sequences` must be a list of iterables. '\n",
        "                             'Found non-iterable: ' + str(x))\n",
        "\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "\n",
        "    # take the sample shape from the first non empty sequence\n",
        "    # checking for consistency in the main loop below.\n",
        "    sample_shape = tuple()\n",
        "    for s in sequences:\n",
        "        if len(s) > 0:\n",
        "            sample_shape = np.asarray(s).shape[1:]\n",
        "            break\n",
        "\n",
        "    is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(dtype, np.unicode_)\n",
        "    if isinstance(value, six.string_types) and dtype != object and not is_dtype_str:\n",
        "        raise ValueError(\"`dtype` {} is not compatible with `value`'s type: {}\\n\"\n",
        "                         \"You should set `dtype=object` for variable length strings.\"\n",
        "                         .format(dtype, type(value)))\n",
        "\n",
        "    x = np.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if not len(s):\n",
        "            continue  # empty list/array was found\n",
        "        if truncating == 'pre':\n",
        "            trunc = s[-maxlen:]\n",
        "        elif truncating == 'post':\n",
        "            trunc = s[:maxlen]\n",
        "        else:\n",
        "            raise ValueError('Truncating type \"%s\" '\n",
        "                             'not understood' % truncating)\n",
        "\n",
        "        # check `trunc` has expected shape\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "        if trunc.shape[1:] != sample_shape:\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s '\n",
        "                             'is different from expected shape %s' %\n",
        "                             (trunc.shape[1:], idx, sample_shape))\n",
        "\n",
        "        if padding == 'post':\n",
        "            x[idx, :len(trunc)] = trunc\n",
        "        elif padding == 'pre':\n",
        "            x[idx, -len(trunc):] = trunc\n",
        "        else:\n",
        "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
        "    return x\n",
        "def Tokenize_with_note_id_hour(df, max_length, tokenizer):\n",
        "    labels = df.Label.values\n",
        "    note_ids = df.Note_ID.values\n",
        "    times = pd.to_datetime(df.charttime.values)\n",
        "    times = times - times.min()\n",
        "    times = times / pd.Timedelta(days=1)\n",
        "    if 'TEXT' in df.columns:\n",
        "        sen = df.TEXT.values\n",
        "        labels = df.Label.values\n",
        "        sen = [\"[CLS] \" + x + \" [SEP]\" for x in sen]\n",
        "        tokenized_texts = [tokenizer.tokenize(x) for x in sen]\n",
        "        print(\"First sentence tokenized\")\n",
        "        print(tokenized_texts[0])\n",
        "        input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    else:\n",
        "        assert 'Input_ID' in df.columns\n",
        "        input_ids = df.Input_ID.apply(lambda x: x.split(' '))\n",
        "        input_ids = input_ids.apply(lambda x: [int(i) for i in x])\n",
        "        input_ids = input_ids.values\n",
        "    input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return labels, input_ids, attention_masks, note_ids, times\n",
        "\n",
        "def reorder_by_time(data):\n",
        "    data.chartdate = pd.to_datetime(data.chartdate)\n",
        "    data.charttime = pd.to_datetime(data.charttime)\n",
        "    data.loc[data.charttime.isna(), 'charttime'] = data[data.charttime.isna()].chartdate + pd.Timedelta(hours=23,\n",
        "                                                                                                        minutes=59,\n",
        "                                                                                                        seconds=59)\n",
        "    data = data.sort_values(by=['Adm_ID', 'charttime', 'Note_ID'])\n",
        "    data.reset_index(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "def concat_by_id_list_with_note_chunk_id_time(df, labels, inputs, masks, note_ids, times, str_len):\n",
        "    final_labels, final_inputs, final_masks, final_note_ids, final_chunk_ids, final_times = [], [], [], [], [], []\n",
        "    id_lists = df.Adm_ID.unique()\n",
        "    for id in id_lists:\n",
        "        id_ix = df.index[df.Adm_ID == id].to_list()\n",
        "        final_inputs.append(inputs[id_ix])\n",
        "        final_masks.append(masks[id_ix])\n",
        "        final_labels.append(labels[id_ix].max())\n",
        "        final_note_ids.append(note_ids[id_ix])\n",
        "        final_chunk_ids.append(torch.tensor(list(range(len(id_ix)))[::-1]))\n",
        "        final_times.append(torch.tensor(np.concatenate([np.zeros(1), np.diff(times[id_ix])])))\n",
        "    return final_labels, final_inputs, final_masks, id_lists, final_note_ids, final_chunk_ids, final_times\n",
        "\n",
        "def convert_note_ids(note_ids):\n",
        "    new_dict = dict(zip(pd.Series(note_ids).unique(), range(len(pd.Series(note_ids).unique()))[::-1]))\n",
        "    new_ids = [new_dict[i] for i in note_ids]\n",
        "    return torch.tensor(new_ids)\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.asarray([1 if i else 0 for i in (preds.flatten() >= 0.5)])\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def Tokenize_with_note_id(df, max_length, tokenizer):\n",
        "    labels = df.Label.values\n",
        "    note_ids = df.Note_ID.values\n",
        "    if 'TEXT' in df.columns:\n",
        "        sen = df.TEXT.values\n",
        "        labels = df.Label.values\n",
        "        sen = [\"[CLS] \" + x + \" [SEP]\" for x in sen]\n",
        "        tokenized_texts = [tokenizer.tokenize(x) for x in sen]\n",
        "        print(\"First sentence tokenized\")\n",
        "        print(tokenized_texts[0])\n",
        "        input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    else:\n",
        "        assert 'Input_ID' in df.columns\n",
        "        input_ids = df.Input_ID.apply(lambda x: x.split(' '))\n",
        "        input_ids = input_ids.apply(lambda x: [int(i) for i in x])\n",
        "        input_ids = input_ids.values\n",
        "    input_ids = pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return labels, input_ids, attention_masks, note_ids\n",
        "\n",
        "def concat_by_id_list_with_note_chunk_id(df, labels, inputs, masks, note_ids, str_len):\n",
        "    final_labels, final_inputs, final_masks, final_note_ids, final_chunk_ids = [], [], [], [], []\n",
        "    id_lists = df.Adm_ID.unique()\n",
        "    for id in id_lists:\n",
        "        id_ix = df.index[df.Adm_ID == id].to_list()\n",
        "        final_inputs.append(inputs[id_ix])\n",
        "        final_masks.append(masks[id_ix])\n",
        "        final_labels.append(labels[id_ix].max())\n",
        "        final_note_ids.append(note_ids[id_ix])\n",
        "        final_chunk_ids.append(torch.tensor(list(range(len(id_ix)))[::-1]))\n",
        "    return final_labels, final_inputs, final_masks, id_lists, final_note_ids, final_chunk_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaEzLWw_wFOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e71721d-b87c-4618-931d-43b87f487130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2609602.79B/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfBbmvB_zfhN"
      },
      "outputs": [],
      "source": [
        "#train_df = reorder_by_time(train_df)\n",
        "#val_df = reorder_by_time(val_df)\n",
        "#test_df = reorder_by_time(test_df)\n",
        "train_labels, train_inputs, train_masks, train_note_ids= Tokenize_with_note_id(train_df, MAX_LEN, tokenizer)\n",
        "validation_labels, validation_inputs, validation_masks, validation_note_ids = Tokenize_with_note_id(val_df, MAX_LEN, tokenizer)\n",
        "test_labels, test_inputs, test_masks, test_note_ids= Tokenize_with_note_id(test_df, MAX_LEN, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NCngu3bmGIw",
        "outputId": "a92ce773-2974-40ce-8929-6b11c2d6a205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Float64Index([22596.270833333332, 22596.270833333332,  22596.46318287037,\n",
              "               22596.80486111111,  22596.80486111111,  22596.80486111111,\n",
              "              22597.241666666665, 22597.241666666665, 22597.241666666665,\n",
              "               22597.46318287037,\n",
              "              ...\n",
              "              431.46318287037036, 431.46318287037036, 431.46318287037036,\n",
              "              431.46318287037036, 431.46318287037036, 431.46318287037036,\n",
              "              431.46318287037036, 431.46318287037036, 431.46318287037036,\n",
              "              431.46318287037036],\n",
              "             dtype='float64', length=444033)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSCXFmTSwKJd"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62nfIf_hwrwp"
      },
      "outputs": [],
      "source": [
        "(train_labels, train_inputs,\n",
        "     train_masks, train_ids,\n",
        "     train_note_ids, train_chunk_ids) = concat_by_id_list_with_note_chunk_id(train_df, train_labels,\n",
        "                                                                                               train_inputs,\n",
        "                                                                                               train_masks,\n",
        "                                                                                               train_note_ids,\n",
        "                                                                                              MAX_LEN)\n",
        "(validation_labels, validation_inputs,\n",
        "     validation_masks, validation_ids,\n",
        "     validation_note_ids, validation_chunk_ids) = concat_by_id_list_with_note_chunk_id(val_df, validation_labels,\n",
        "                                                                   validation_inputs, validation_masks,\n",
        "                                                                   validation_note_ids,\n",
        "                                                                   MAX_LEN)\n",
        "(test_labels, test_inputs,\n",
        "     test_masks, test_ids,\n",
        "     test_note_ids, test_chunk_ids) = concat_by_id_list_with_note_chunk_id(test_df, test_labels,\n",
        "                                                                                            test_inputs, test_masks,\n",
        "                                                                                            test_note_ids,\n",
        "                                                                                            MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zss6Rs-Em9zc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import logging\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "import sys\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import boto3\n",
        "from functools import wraps\n",
        "from hashlib import sha256\n",
        "from botocore.exceptions import ClientError\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = Path(os.getenv('PYTORCH_PRETRAINED_BERT_CACHE',\n",
        "                                                   Path.home() / '.pytorch_pretrained_bert'))\n",
        "def url_to_filename(url, etag=None):\n",
        "    \"\"\"\n",
        "    Convert `url` into a hashed filename in a repeatable way.\n",
        "    If `etag` is specified, append its hash to the url's, delimited\n",
        "    by a period.\n",
        "    \"\"\"\n",
        "    url_bytes = url.encode('utf-8')\n",
        "    url_hash = sha256(url_bytes)\n",
        "    filename = url_hash.hexdigest()\n",
        "\n",
        "    if etag:\n",
        "        etag_bytes = etag.encode('utf-8')\n",
        "        etag_hash = sha256(etag_bytes)\n",
        "        filename += '.' + etag_hash.hexdigest()\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def filename_to_url(filename, cache_dir=None):\n",
        "    \"\"\"\n",
        "    Return the url and etag (which may be ``None``) stored for `filename`.\n",
        "    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n",
        "    \"\"\"\n",
        "    if cache_dir is None:\n",
        "        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE\n",
        "    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):\n",
        "        cache_dir = str(cache_dir)\n",
        "\n",
        "    cache_path = os.path.join(cache_dir, filename)\n",
        "    if not os.path.exists(cache_path):\n",
        "        raise EnvironmentError(\"file {} not found\".format(cache_path))\n",
        "\n",
        "    meta_path = cache_path + '.json'\n",
        "    if not os.path.exists(meta_path):\n",
        "        raise EnvironmentError(\"file {} not found\".format(meta_path))\n",
        "\n",
        "    with open(meta_path, encoding=\"utf-8\") as meta_file:\n",
        "        metadata = json.load(meta_file)\n",
        "    url = metadata['url']\n",
        "    etag = metadata['etag']\n",
        "\n",
        "    return url, etag\n",
        "\n",
        "\n",
        "def cached_path(url_or_filename, cache_dir=None):\n",
        "    \"\"\"\n",
        "    Given something that might be a URL (or might be a local path),\n",
        "    determine which. If it's a URL, download the file and cache it, and\n",
        "    return the path to the cached file. If it's already a local path,\n",
        "    make sure the file exists and then return the path.\n",
        "    \"\"\"\n",
        "    if cache_dir is None:\n",
        "        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE\n",
        "    if sys.version_info[0] == 3 and isinstance(url_or_filename, Path):\n",
        "        url_or_filename = str(url_or_filename)\n",
        "    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):\n",
        "        cache_dir = str(cache_dir)\n",
        "\n",
        "    parsed = urlparse(url_or_filename)\n",
        "\n",
        "    if parsed.scheme in ('http', 'https', 's3'):\n",
        "        # URL, so get it from the cache (downloading if necessary)\n",
        "        return get_from_cache(url_or_filename, cache_dir)\n",
        "    elif os.path.exists(url_or_filename):\n",
        "        # File, and it exists.\n",
        "        return url_or_filename\n",
        "    elif parsed.scheme == '':\n",
        "        # File, but it doesn't exist.\n",
        "        raise EnvironmentError(\"file {} not found\".format(url_or_filename))\n",
        "    else:\n",
        "        # Something unknown\n",
        "        raise ValueError(\"unable to parse {} as a URL or as a local path\".format(url_or_filename))\n",
        "\n",
        "\n",
        "def split_s3_path(url):\n",
        "    \"\"\"Split a full s3 path into the bucket name and path.\"\"\"\n",
        "    parsed = urlparse(url)\n",
        "    if not parsed.netloc or not parsed.path:\n",
        "        raise ValueError(\"bad s3 path {}\".format(url))\n",
        "    bucket_name = parsed.netloc\n",
        "    s3_path = parsed.path\n",
        "    # Remove '/' at beginning of path.\n",
        "    if s3_path.startswith(\"/\"):\n",
        "        s3_path = s3_path[1:]\n",
        "    return bucket_name, s3_path\n",
        "\n",
        "\n",
        "def s3_request(func):\n",
        "    \"\"\"\n",
        "    Wrapper function for s3 requests in order to create more helpful error\n",
        "    messages.\n",
        "    \"\"\"\n",
        "\n",
        "    @wraps(func)\n",
        "    def wrapper(url, *args, **kwargs):\n",
        "        try:\n",
        "            return func(url, *args, **kwargs)\n",
        "        except ClientError as exc:\n",
        "            if int(exc.response[\"Error\"][\"Code\"]) == 404:\n",
        "                raise EnvironmentError(\"file {} not found\".format(url))\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@s3_request\n",
        "def s3_etag(url):\n",
        "    \"\"\"Check ETag on S3 object.\"\"\"\n",
        "    s3_resource = boto3.resource(\"s3\")\n",
        "    bucket_name, s3_path = split_s3_path(url)\n",
        "    s3_object = s3_resource.Object(bucket_name, s3_path)\n",
        "    return s3_object.e_tag\n",
        "\n",
        "\n",
        "@s3_request\n",
        "def s3_get(url, temp_file):\n",
        "    \"\"\"Pull a file directly from S3.\"\"\"\n",
        "    s3_resource = boto3.resource(\"s3\")\n",
        "    bucket_name, s3_path = split_s3_path(url)\n",
        "    s3_resource.Bucket(bucket_name).download_fileobj(s3_path, temp_file)\n",
        "\n",
        "\n",
        "def http_get(url, temp_file):\n",
        "    req = requests.get(url, stream=True)\n",
        "    content_length = req.headers.get('Content-Length')\n",
        "    total = int(content_length) if content_length is not None else None\n",
        "    progress = tqdm(unit=\"B\", total=total)\n",
        "    for chunk in req.iter_content(chunk_size=1024):\n",
        "        if chunk: # filter out keep-alive new chunks\n",
        "            progress.update(len(chunk))\n",
        "            temp_file.write(chunk)\n",
        "    progress.close()\n",
        "\n",
        "\n",
        "def get_from_cache(url, cache_dir=None):\n",
        "    \"\"\"\n",
        "    Given a URL, look for the corresponding dataset in the local cache.\n",
        "    If it's not there, download it. Then return the path to the cached file.\n",
        "    \"\"\"\n",
        "    if cache_dir is None:\n",
        "        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE\n",
        "    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):\n",
        "        cache_dir = str(cache_dir)\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "        os.makedirs(cache_dir)\n",
        "\n",
        "    # Get eTag to add to filename, if it exists.\n",
        "    if url.startswith(\"s3://\"):\n",
        "        etag = s3_etag(url)\n",
        "    else:\n",
        "        response = requests.head(url, allow_redirects=True)\n",
        "        if response.status_code != 200:\n",
        "            raise IOError(\"HEAD request failed for url {} with status code {}\"\n",
        "                          .format(url, response.status_code))\n",
        "        etag = response.headers.get(\"ETag\")\n",
        "\n",
        "    filename = url_to_filename(url, etag)\n",
        "\n",
        "    # get cache path to put the file\n",
        "    cache_path = os.path.join(cache_dir, filename)\n",
        "\n",
        "    if not os.path.exists(cache_path):\n",
        "        # Download to temporary file, then copy to cache dir once finished.\n",
        "        # Otherwise you get corrupt cache entries if the download gets interrupted.\n",
        "        with tempfile.NamedTemporaryFile() as temp_file:\n",
        "            logger.info(\"%s not found in cache, downloading to %s\", url, temp_file.name)\n",
        "\n",
        "            # GET file object\n",
        "            if url.startswith(\"s3://\"):\n",
        "                s3_get(url, temp_file)\n",
        "            else:\n",
        "                http_get(url, temp_file)\n",
        "\n",
        "            # we are copying the file before closing it, so flush to avoid truncation\n",
        "            temp_file.flush()\n",
        "            # shutil.copyfileobj() starts at the current position, so go to the start\n",
        "            temp_file.seek(0)\n",
        "\n",
        "            logger.info(\"copying %s to cache at %s\", temp_file.name, cache_path)\n",
        "            with open(cache_path, 'wb') as cache_file:\n",
        "                shutil.copyfileobj(temp_file, cache_file)\n",
        "\n",
        "            logger.info(\"creating metadata file for %s\", cache_path)\n",
        "            meta = {'url': url, 'etag': etag}\n",
        "            meta_path = cache_path + '.json'\n",
        "            with open(meta_path, 'w', encoding=\"utf-8\") as meta_file:\n",
        "                json.dump(meta, meta_file)\n",
        "\n",
        "            logger.info(\"removing temp file %s\", temp_file.name)\n",
        "\n",
        "    return cache_path\n",
        "\n",
        "\n",
        "def read_set_from_file(filename):\n",
        "    '''\n",
        "    Extract a de-duped collection (set) of text from a file.\n",
        "    Expected file format is one item per line.\n",
        "    '''\n",
        "    collection = set()\n",
        "    with open(filename, 'r', encoding='utf-8') as file_:\n",
        "        for line in file_:\n",
        "            collection.add(line.rstrip())\n",
        "    return collection\n",
        "\n",
        "\n",
        "def get_file_extension(path, dot=True, lower=True):\n",
        "    ext = os.path.splitext(path)[1]\n",
        "    ext = ext if dot else ext[1:]\n",
        "    return ext.lower() if lower else ext\n",
        "\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
        "    'bert-base-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\",\n",
        "    'bert-large-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz\",\n",
        "    'bert-base-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz\",\n",
        "    'bert-base-multilingual': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual.tar.gz\",\n",
        "    'bert-base-chinese': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz\",\n",
        "}\n",
        "CONFIG_NAME = 'bert_config.json'\n",
        "WEIGHTS_NAME = 'pytorch_model.bin'\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\n",
        "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
        "\n",
        "\n",
        "class BertConfig(object):\n",
        "    \"\"\"Configuration class to store the configuration of a `BertModel`.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 num_attention_heads=12,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        \"\"\"Constructs BertConfig.\n",
        "\n",
        "        Args:\n",
        "            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n",
        "            hidden_size: Size of the encoder layers and the pooler layer.\n",
        "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
        "            num_attention_heads: Number of attention heads for each attention layer in\n",
        "                the Transformer encoder.\n",
        "            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
        "                layer in the Transformer encoder.\n",
        "            hidden_act: The non-linear activation function (function or string) in the\n",
        "                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n",
        "            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
        "                layers in the embeddings, encoder, and pooler.\n",
        "            attention_probs_dropout_prob: The dropout ratio for the attention\n",
        "                probabilities.\n",
        "            max_position_embeddings: The maximum sequence length that this model might\n",
        "                ever be used with. Typically set this to something large just in case\n",
        "                (e.g., 512 or 1024 or 2048).\n",
        "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
        "                `BertModel`.\n",
        "            initializer_range: The sttdev of the truncated_normal_initializer for\n",
        "                initializing all weight matrices.\n",
        "        \"\"\"\n",
        "        if isinstance(vocab_size_or_config_json_file, str):\n",
        "            with open(vocab_size_or_config_json_file, \"r\") as reader:\n",
        "                json_config = json.loads(reader.read())\n",
        "            for key, value in json_config.items():\n",
        "                self.__dict__[key] = value\n",
        "        elif isinstance(vocab_size_or_config_json_file, int):\n",
        "            self.vocab_size = vocab_size_or_config_json_file\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_hidden_layers = num_hidden_layers\n",
        "            self.num_attention_heads = num_attention_heads\n",
        "            self.hidden_act = hidden_act\n",
        "            self.intermediate_size = intermediate_size\n",
        "            self.hidden_dropout_prob = hidden_dropout_prob\n",
        "            self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "            self.max_position_embeddings = max_position_embeddings\n",
        "            self.type_vocab_size = type_vocab_size\n",
        "            self.initializer_range = initializer_range\n",
        "        else:\n",
        "            raise ValueError(\"First argument must be either a vocabulary size (int)\"\n",
        "                             \"or the path to a pretrained model config file (str)\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, json_object):\n",
        "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n",
        "        config = BertConfig(vocab_size_or_config_json_file=-1)\n",
        "        for key, value in json_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_json_file(cls, json_file):\n",
        "        \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n",
        "        with open(json_file, \"r\") as reader:\n",
        "            text = reader.read()\n",
        "        return cls.from_dict(json.loads(text))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "\n",
        "class BertLayerNorm(nn.Module):\n",
        "    def __init__(self, config, variance_epsilon=1e-12):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(BertLayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(config.hidden_size))\n",
        "        self.beta = nn.Parameter(torch.zeros(config.hidden_size))\n",
        "        self.variance_epsilon = variance_epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.gamma * x + self.beta\n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        return context_layer\n",
        "\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output = self.self(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        self.intermediate_act_fn = ACT2FN[config.hidden_act] \\\n",
        "            if isinstance(config.hidden_act, str) else config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
        "        # any TensorFlow checkpoint file\n",
        "        self.LayerNorm = BertLayerNorm(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "        self.attention = BertAttention(config)\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        attention_output = self.attention(hidden_states, attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "        layer = BertLayer(config)\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            hidden_states = layer_module(hidden_states, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "        return all_encoder_layers\n",
        "\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "class PreTrainedBertModel(nn.Module):\n",
        "    \"\"\" An abstract class to handle weights initialization and\n",
        "        a simple interface for dowloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(PreTrainedBertModel, self).__init__()\n",
        "        if not isinstance(config, BertConfig):\n",
        "            raise ValueError(\n",
        "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
        "                \"To create a model from a Google pretrained model use \"\n",
        "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
        "                    self.__class__.__name__, self.__class__.__name__\n",
        "                ))\n",
        "        self.config = config\n",
        "\n",
        "    def init_bert_weights(self, module):\n",
        "        \"\"\" Initialize the weights.\n",
        "        \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, BertLayerNorm):\n",
        "            module.beta.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            module.gamma.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name, *inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Instantiate a PreTrainedBertModel from a pre-trained model file.\n",
        "        Download and cache the pre-trained model file if needed.\n",
        "\n",
        "        Params:\n",
        "            pretrained_model_name: either:\n",
        "                - a str with the name of a pre-trained model to load selected in the list of:\n",
        "                    . `bert-base-uncased`\n",
        "                    . `bert-large-uncased`\n",
        "                    . `bert-base-cased`\n",
        "                    . `bert-base-multilingual`\n",
        "                    . `bert-base-chinese`\n",
        "                - a path or url to a pretrained model archive containing:\n",
        "                    . `bert_config.json` a configuration file for the model\n",
        "                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n",
        "            *inputs, **kwargs: additional input for the specific Bert class\n",
        "                (ex: num_labels for BertForSequenceClassification)\n",
        "        \"\"\"\n",
        "        if pretrained_model_name in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
        "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name]\n",
        "        else:\n",
        "            archive_file = pretrained_model_name\n",
        "        # redirect to the cache, if necessary\n",
        "        try:\n",
        "            resolved_archive_file = cached_path(archive_file)\n",
        "        except FileNotFoundError:\n",
        "            logger.error(\n",
        "                \"Model name '{}' was not found in model name list ({}). \"\n",
        "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
        "                \"associated to this path or url.\".format(\n",
        "                    pretrained_model_name,\n",
        "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),\n",
        "                    pretrained_model_name))\n",
        "            return None\n",
        "        if resolved_archive_file == archive_file:\n",
        "            logger.info(\"loading archive file {}\".format(archive_file))\n",
        "        else:\n",
        "            logger.info(\"loading archive file {} from cache at {}\".format(\n",
        "                archive_file, resolved_archive_file))\n",
        "        tempdir = None\n",
        "        if os.path.isdir(resolved_archive_file):\n",
        "            serialization_dir = resolved_archive_file\n",
        "        else:\n",
        "            # Extract archive to temp dir\n",
        "            tempdir = tempfile.mkdtemp()\n",
        "            logger.info(\"extracting archive file {} to temp dir {}\".format(\n",
        "                resolved_archive_file, tempdir))\n",
        "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
        "                archive.extractall(tempdir)\n",
        "            serialization_dir = tempdir\n",
        "        # Load config\n",
        "        config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
        "        config = BertConfig.from_json_file(config_file)\n",
        "        logger.info(\"Model config {}\".format(config))\n",
        "        # Instantiate model.\n",
        "        model = cls(config, *inputs, **kwargs)\n",
        "        weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
        "        state_dict = torch.load(weights_path, map_location = 'cpu')\n",
        "\n",
        "        missing_keys = []\n",
        "        unexpected_keys = []\n",
        "        error_msgs = []\n",
        "        # copy state_dict so _load_from_state_dict can modify it\n",
        "        metadata = getattr(state_dict, '_metadata', None)\n",
        "        state_dict = state_dict.copy()\n",
        "        if metadata is not None:\n",
        "            state_dict._metadata = metadata\n",
        "\n",
        "        def load(module, prefix=''):\n",
        "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "            module._load_from_state_dict(\n",
        "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        load(model, prefix='' if hasattr(model, 'bert') else 'bert.')\n",
        "        if len(missing_keys) > 0:\n",
        "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "                model.__class__.__name__, missing_keys))\n",
        "        if len(unexpected_keys) > 0:\n",
        "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "                model.__class__.__name__, unexpected_keys))\n",
        "        if tempdir:\n",
        "            # Clean up temp dir\n",
        "            shutil.rmtree(tempdir)\n",
        "        return model\n",
        "\n",
        "class BertModel(PreTrainedBertModel):\n",
        "    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
        "\n",
        "    Params:\n",
        "        config: a BertConfig class instance with the configuration to build a new model\n",
        "\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
        "\n",
        "    Outputs: Tuple of (encoded_layers, pooled_output)\n",
        "        `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
        "            - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
        "                of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
        "                encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
        "            - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
        "                to the last attention block,\n",
        "        `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
        "            classifier pretrained on top of the hidden state associated to the first character of the\n",
        "            input (`CLF`) to train on the Next-Sentence task (see BERT's paper).\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
        "\n",
        "    config = modeling.BertConfig(vocab_size=32000, hidden_size=512,\n",
        "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
        "\n",
        "    model = modeling.BertModel(config=config)\n",
        "    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertModel, self).__init__(config)\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        # We create a 3D attention mask from a 2D tensor mask.\n",
        "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
        "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
        "        # this attention mask is more simple than the triangular masking of causal attention\n",
        "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      extended_attention_mask,\n",
        "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
        "        sequence_output = encoded_layers[-1]\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "        return encoded_layers, pooled_output\n",
        "\n",
        "\n",
        "class BertForSequenceClassification(PreTrainedBertModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits.\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n",
        "\n",
        "    config = BertConfig(vocab_size=32000, hidden_size=512,\n",
        "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
        "\n",
        "    num_labels = 2\n",
        "\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "\n",
        "        pooled_output2 = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output2)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCELoss()\n",
        "            m = nn.Sigmoid()\n",
        "            n = torch.squeeze(m(logits))\n",
        "            loss = loss_fct(n, labels.float())\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUoES0RcCWOw"
      },
      "outputs": [],
      "source": [
        "class PatientLevelEmbedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(PatientLevelEmbedding, self).__init__()\n",
        "        self.config = config\n",
        "        assert self.config.embed_mode in [\"all\", \"note\", \"chunk\", \"no\"]\n",
        "        if self.config.embed_mode == \"all\":\n",
        "            self.note_embedding = nn.Embedding(self.config.max_note_position_embedding, self.config.hidden_size)\n",
        "            self.chunk_embedding = nn.Embedding(self.config.max_chunk_position_embedding, self.config.hidden_size)\n",
        "            self.combine_embed_rep = nn.Linear(self.config.hidden_size * 3, self.config.hidden_size)\n",
        "        elif self.config.embed_mode == \"note\":\n",
        "            self.note_embedding = nn.Embedding(self.config.max_note_position_embedding, self.config.hidden_size)\n",
        "            self.combine_embed_rep = nn.Linear(self.config.hidden_size * 2, self.config.hidden_size)\n",
        "        elif self.config.embed_mode == \"chunk\":\n",
        "            self.chunk_embedding = nn.Embedding(self.config.max_chunk_position_embedding, self.config.hidden_size)\n",
        "            self.combine_embed_rep = nn.Linear(self.config.hidden_size * 2, self.config.hidden_size)\n",
        "        else:\n",
        "            pass\n",
        "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, inputs, new_note_ids=None, new_chunk_ids=None):\n",
        "        if self.config.embed_mode == \"all\":\n",
        "            note_embeds = self.note_embedding(new_note_ids)\n",
        "            chunk_embeds = self.chunk_embedding(new_chunk_ids)\n",
        "            output = self.combine_embed_rep(torch.cat((inputs, note_embeds, chunk_embeds), 2))\n",
        "        elif self.config.embed_mode == \"note\":\n",
        "            note_embeds = self.note_embedding(new_note_ids)\n",
        "            output = self.combine_embed_rep(torch.cat((inputs, note_embeds), 2))\n",
        "        elif self.config.embed_mode == \"chunk\":\n",
        "            chunk_embeds = self.chunk_embedding(new_chunk_ids)\n",
        "            output = self.combine_embed_rep(torch.cat((inputs, chunk_embeds), 2))\n",
        "        elif self.config.embed_mode == \"no\":\n",
        "            output = inputs\n",
        "        else:\n",
        "            raise ValueError(\"The embed mode: {} is not supported\".format(self.config.embed_mode))\n",
        "        if self.config.embed_mode != \"no\":\n",
        "            output = self.LayerNorm(output)\n",
        "            output = self.dropout(output)\n",
        "        return output\n",
        "\n",
        "class SelfDefineBert(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SelfDefineBert, self).__init__()\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        \"\"\" Initialize the weights \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "class FTLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, config, batch_first=True, bidirectional=True):\n",
        "        super(FTLSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_first = batch_first\n",
        "        self.bidirectional = bidirectional\n",
        "        self.c1 = torch.Tensor([1]).float()\n",
        "        self.c2 = torch.Tensor([np.e]).float()\n",
        "        self.c3 = torch.Tensor([0.]).float()\n",
        "        self.ones = torch.ones([1, self.hidden_size]).float()\n",
        "        self.register_buffer('c1_const', self.c1)\n",
        "        self.register_buffer('c2_const', self.c2)\n",
        "        self.register_buffer('c3_const', self.c3)\n",
        "        self.register_buffer(\"ones_const\", self.ones)\n",
        "        # Input Gate Parameter\n",
        "        self.Wi = Parameter(torch.normal(0.0, config.initializer_range, size=(self.input_size, self.hidden_size)))\n",
        "        self.Ui = Parameter(torch.normal(0.0, config.initializer_range, size=(self.hidden_size, self.hidden_size)))\n",
        "        self.bi = Parameter(torch.zeros(self.hidden_size))\n",
        "        # Forget Gate Parameter\n",
        "        self.Wf = Parameter(torch.normal(0.0, config.initializer_range, size=(self.input_size, self.hidden_size)))\n",
        "        self.Uf = Parameter(torch.normal(0.0, config.initializer_range, size=(self.hidden_size, self.hidden_size)))\n",
        "        self.bf = Parameter(torch.zeros(self.hidden_size))\n",
        "        # Output Gate Parameter\n",
        "        self.Wog = Parameter(torch.normal(0.0, config.initializer_range, size=(self.input_size, self.hidden_size)))\n",
        "        self.Uog = Parameter(torch.normal(0.0, config.initializer_range, size=(self.hidden_size, self.hidden_size)))\n",
        "        self.bog = Parameter(torch.zeros(self.hidden_size))\n",
        "        # Cell Layer Parameter\n",
        "        self.Wc = Parameter(torch.normal(0.0, config.initializer_range, size=(self.input_size, self.hidden_size)))\n",
        "        self.Uc = Parameter(torch.normal(0.0, config.initializer_range, size=(self.hidden_size, self.hidden_size)))\n",
        "        self.bc = Parameter(torch.zeros(self.hidden_size))\n",
        "        # Decomposition Layer Parameter\n",
        "        self.W_decomp = Parameter(\n",
        "            torch.normal(0.0, config.initializer_range, size=(self.hidden_size, self.hidden_size)))\n",
        "        self.b_decomp = Parameter(torch.zeros(self.hidden_size))\n",
        "        # Decay Parameter\n",
        "        self.W_decay_1 = Parameter(torch.tensor([[0.33]]))\n",
        "        self.W_decay_2 = Parameter(torch.tensor([[0.33]]))\n",
        "        self.W_decay_3 = Parameter(torch.tensor([[0.33]]))\n",
        "        self.a = Parameter(torch.tensor([1.0]))\n",
        "        self.b = Parameter(torch.tensor([1.0]))\n",
        "        self.m = Parameter(torch.tensor([0.02]))\n",
        "        self.k = Parameter(torch.tensor([2.9]))\n",
        "        self.d = Parameter(torch.tensor([4.5]))\n",
        "        self.n = Parameter(torch.tensor([2.5]))\n",
        "\n",
        "    def FTLSTM_unit(self, prev_hidden_memory, inputs, times):\n",
        "        prev_hidden_state, prev_cell = prev_hidden_memory\n",
        "        x = inputs\n",
        "        t = times\n",
        "        T = self.map_elapse_time(t)\n",
        "        C_ST = torch.tanh(torch.matmul(prev_cell, self.W_decomp) + self.b_decomp)\n",
        "        C_ST_dis = torch.mul(T, C_ST)\n",
        "        prev_cell = prev_cell - C_ST + C_ST_dis\n",
        "\n",
        "        # Input Gate\n",
        "        i = torch.sigmoid(torch.matmul(x, self.Wi) +\n",
        "                          torch.matmul(prev_hidden_state, self.Ui) + self.bi)\n",
        "        # Forget Gate\n",
        "        f = torch.sigmoid(torch.matmul(x, self.Wf) +\n",
        "                          torch.matmul(prev_hidden_state, self.Uf) + self.bf)\n",
        "        # Output Gate\n",
        "        o = torch.sigmoid(torch.matmul(x, self.Wog) +\n",
        "                          torch.matmul(prev_hidden_state, self.Uog) + self.bog)\n",
        "        # Candidate Memory Cell\n",
        "        C = torch.sigmoid(torch.matmul(x, self.Wc) +\n",
        "                          torch.matmul(prev_hidden_state, self.Uc) + self.bc)\n",
        "        # Current Memory Cell\n",
        "        Ct = f * prev_cell + i * C\n",
        "\n",
        "        # Current Hidden State\n",
        "        current_hidden_state = o * torch.tanh(Ct)\n",
        "\n",
        "        return current_hidden_state, Ct\n",
        "\n",
        "    def map_elapse_time(self, t):\n",
        "        T_1 = torch.div(self.c1_const, torch.mul(self.a, torch.pow(t, self.b)))\n",
        "        T_2 = self.k - torch.mul(self.m, t)\n",
        "        T_3 = torch.div(self.c1_const, (self.c1_const + torch.pow(torch.div(t, self.d), self.n)))\n",
        "        T = torch.mul(self.W_decay_1, T_1) + torch.mul(self.W_decay_2, T_2) + torch.mul(self.W_decay_3, T_3)\n",
        "        T = torch.max(T, self.c3_const)\n",
        "        T = torch.min(T, self.c1_const)\n",
        "        T = torch.matmul(T, self.ones_const)\n",
        "        return T\n",
        "\n",
        "    def forward(self, inputs, times):\n",
        "        device = inputs.device\n",
        "        if self.batch_first:\n",
        "            batch_size = inputs.size()[0]\n",
        "            inputs = inputs.permute(1, 0, 2)\n",
        "            times = times.transpose(0, 1)\n",
        "        else:\n",
        "            batch_size = inputs.size()[1]\n",
        "        prev_hidden = torch.zeros((batch_size, self.hidden_size), device=device)\n",
        "        prev_cell = torch.zeros((batch_size, self.hidden_size), device=device)\n",
        "        seq_len = inputs.size()[0]\n",
        "        hidden_his = []\n",
        "        for i in range(seq_len):\n",
        "            prev_hidden, prev_cell = self.FTLSTM_unit((prev_hidden, prev_cell), inputs[i], times[i])\n",
        "            hidden_his.append(prev_hidden)\n",
        "        hidden_his = torch.stack(hidden_his)\n",
        "        if self.bidirectional:\n",
        "            second_hidden = torch.zeros((batch_size, self.hidden_size), device=device)\n",
        "            second_cell = torch.zeros((batch_size, self.hidden_size), device=device)\n",
        "            second_inputs = torch.flip(inputs, [0])\n",
        "            second_times = torch.flip(times, [0])\n",
        "            second_hidden_his = []\n",
        "            for i in range(seq_len):\n",
        "                if i == 0:\n",
        "                    time = times[i]\n",
        "                else:\n",
        "                    time = second_times[i-1]\n",
        "                second_hidden, second_cell = self.FTLSTM_unit((second_hidden, second_cell), second_inputs[i], time)\n",
        "                second_hidden_his.append(second_hidden)\n",
        "            second_hidden_his = torch.stack(second_hidden_his)\n",
        "            hidden_his = torch.cat((hidden_his, second_hidden_his), dim=2)\n",
        "            prev_hidden = torch.cat((prev_hidden, second_hidden), dim=1)\n",
        "            prev_cell = torch.cat((prev_cell, second_cell), dim=1)\n",
        "        if self.batch_first:\n",
        "            hidden_his = hidden_his.permute(1, 0, 2)\n",
        "        return hidden_his, (prev_hidden, prev_cell)\n",
        "\n",
        "class FTLSTMLayer(SelfDefineBert):\n",
        "\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(FTLSTMLayer, self).__init__()\n",
        "        self.config = config\n",
        "        self.ftlstm = FTLSTM(self.config.hidden_size,\n",
        "                           self.config.hidden_size // 2,\n",
        "                           self.config,\n",
        "                           batch_first=True,\n",
        "                           bidirectional=True)\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.embeddings = PatientLevelEmbedding(config)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def forward(self, inputs, times, new_note_ids=None, new_chunk_ids=None, labels=None):\n",
        "        new_input = self.embeddings(inputs, new_note_ids, new_chunk_ids)\n",
        "        lstm_output, hidden = self.ftlstm(new_input, times.float())\n",
        "        loss_fct = BCEWithLogitsLoss()\n",
        "        drop_input = lstm_output[0, -1, :]\n",
        "        class_input = self.dropout(drop_input)\n",
        "        logits = self.classifier(class_input)\n",
        "        logits = torch.where(torch.isnan(logits), torch.zeros_like(logits), logits)\n",
        "        logits = torch.where(torch.isinf(logits), torch.zeros_like(logits), logits)\n",
        "        pred = torch.sigmoid(logits)\n",
        "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
        "        pred = torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
        "        if labels is not None:\n",
        "            loss = loss_fct(logits, labels.float().view(1))\n",
        "            return loss, pred\n",
        "        else:\n",
        "            return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mIGKxzbDqhP"
      },
      "outputs": [],
      "source": [
        "def time_batch_generator(max_len, input_ids, labels, masks, note_ids, chunk_ids, times=None):\n",
        "    \"\"\"batch generator with note_id, chunk_id and time\n",
        "    \"\"\"\n",
        "    size = len(input_ids)\n",
        "    indices = np.arange(size)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i < size:\n",
        "            if times is not None:\n",
        "                yield input_ids[indices[i]][-max_len:, :], labels[indices[i]], masks[indices[i]][-max_len:, :], \\\n",
        "                      note_ids[indices[i]][-max_len:], chunk_ids[indices[i]][-max_len:], times[indices[i]][-max_len:]\n",
        "            else:\n",
        "                yield input_ids[indices[i]][-max_len:, :], labels[indices[i]], masks[indices[i]][-max_len:, :], \\\n",
        "                      note_ids[indices[i]][-max_len:], chunk_ids[indices[i]][-max_len:]\n",
        "            i += 1\n",
        "        else:\n",
        "            i = 0\n",
        "            indices = np.arange(size)\n",
        "            np.random.shuffle(indices)\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-waNJRLosbx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DotMap()\n",
        "config.hidden_dropout_prob = 0.1\n",
        "config.layer_norm_eps = 1e-12\n",
        "config.initializer_range = 0.02\n",
        "config.max_note_position_embedding = 1000\n",
        "config.max_chunk_position_embedding = 1000\n",
        "config.embed_mode = 'None'\n",
        "config.layer_norm_eps = 1e-12\n",
        "config.hidden_size = 768\n",
        "config.lstm_layers = 1\n",
        "\n",
        "config.task_name = 'Bert_Prediction'"
      ],
      "metadata": {
        "id": "njD5vIz1kwqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBBFVXd1cpON",
        "outputId": "604a236d-1b09-47d8-8788-09e3ac37ea9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DotMap(hidden_dropout_prob=0.1, layer_norm_eps=1e-12, initializer_range=0.02, max_note_position_embedding=1000, max_chunk_position_embedding=1000, embed_mode='all', hidden_size=768, lstm_layers=1, task_name='FTL-Trans_Prediction', _ipython_display_=DotMap(), _repr_mimebundle_=DotMap())"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_batch_generator(max_len, input_ids, labels, masks):\n",
        "    \"\"\"batch generator\n",
        "    \"\"\"\n",
        "    size = len(input_ids)\n",
        "    indices = np.arange(size)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i < size:\n",
        "            yield input_ids[indices[i]][-max_len:, :], labels[indices[i]], masks[indices[i]][-max_len:, :]\n",
        "            i += 1\n",
        "        else:\n",
        "            i = 0\n",
        "            indices = np.arange(size)\n",
        "            np.random.shuffle(indices)\n",
        "            continue"
      ],
      "metadata": {
        "id": "A6IBXxa2wlnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "IFXzT3ujzkKH",
        "outputId": "6a302de1-1c42-48d2-affc-93b4aea9ad72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:   0%|          | 0/3 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f59d313f2a6e>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-af38611f85eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3113\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3114\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size."
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "if n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "param_optimizer = list(model.named_parameters()) #+ list(lstm_layer.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "num_train_steps = int(\n",
        "    len(train_df) / 1 * 3)\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=2e-5,\n",
        "                         warmup=0.0,\n",
        "                         t_total=num_train_steps)\n",
        "m = torch.nn.Softmax(dim=1)\n",
        "start = time.time()\n",
        "    # Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "    # Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "train_batch_generator = mask_batch_generator(32, train_inputs, train_labels, train_masks)\n",
        "validation_batch_generator = mask_batch_generator(32, validation_inputs, validation_labels,\n",
        "                                                      validation_masks)\n",
        "\n",
        "with torch.autograd.set_detect_anomaly(True):\n",
        "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "            # Training\n",
        "\n",
        "            # Set our model to training mode (as opposed to evaluation mode)\n",
        "        model.train()\n",
        "\n",
        "\n",
        "            # Tracking variables\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "            # Train the data for one epoch\n",
        "        tr_ids_num = len(train_ids)\n",
        "        tr_batch_loss = []\n",
        "        for step in range(tr_ids_num):\n",
        "            b_input_ids, b_labels, b_input_mask = next(train_batch_generator)\n",
        "            b_input_ids = b_input_ids.to(device)\n",
        "            b_input_mask = b_input_mask.to(device)\n",
        "            b_labels = b_labels.repeat(b_input_ids.shape[0]).to(device)\n",
        "                # Forward pass\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            loss, logits = outputs[:2]\n",
        "\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "            tr_batch_loss.append(loss.item())\n",
        "\n",
        "                # Backward pass\n",
        "            loss.backward()\n",
        "                # Update parameters and take a step using the computed gradient\n",
        "            if (step + 1) % 32 == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                train_loss_set.append(np.mean(tr_batch_loss))\n",
        "                tr_batch_loss = []\n",
        "                # Update tracking variables\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "\n",
        "            # Validation\n",
        "\n",
        "            # Put model in evaluation mode to evaluate loss on the validation set\n",
        "        model.eval()\n",
        "\n",
        "            # Tracking variables\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "            # Evaluate data for one epoch\n",
        "        ev_ids_num = len(validation_ids)\n",
        "        for step in range(ev_ids_num):\n",
        "            with torch.no_grad():\n",
        "                b_input_ids, b_labels, b_input_mask = next(validation_batch_generator)\n",
        "                b_input_ids = b_input_ids.to(device)\n",
        "                b_input_mask = b_input_mask.to(device)\n",
        "                b_labels = b_labels.repeat(b_input_ids.shape[0])\n",
        "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "                    # Move logits and labels to CPU\n",
        "                logits = outputs[-1]\n",
        "                logits = m(logits).detach().cpu().numpy()[:, 1]\n",
        "                label_ids = b_labels.numpy()\n",
        "                tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "            #if n_gpu > 1:\n",
        "            #        torch.save({\n",
        "            #            'epoch': epoch,\n",
        "            #            'model_state_dict': model.module.state_dict(),\n",
        "            #            'lstm_layer_state_dict': lstm_layer.module.state_dict(),\n",
        "            #            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            #            'loss': loss,\n",
        "            #        },\n",
        "            #            output_checkpoints_path)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "\n",
        "\n",
        "fig1 = plt.figure(figsize=(15, 8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Patient Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCIStHnSzlql"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "    # Tracking variables\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "    # Predict\n",
        "te_ids_num = len(test_ids)\n",
        "for step in range(te_ids_num):\n",
        "    b_input_ids = test_inputs[step][-args.max_chunk_num:, :].to(device)\n",
        "    b_input_mask = test_masks[step][-args.max_chunk_num:, :].to(device)\n",
        "    b_labels = test_labels[step].repeat(b_input_ids.shape[0])\n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        # outputs' shape: [batch size, 1]\n",
        "logits = torch.squeeze(m(outputs)).detach().cpu().numpy().mean()\n",
        "label_ids = b_labels.numpy().max()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "predictions.append(logits)\n",
        "true_labels.append(label_ids)\n",
        "\n",
        "flat_logits = predictions\n",
        "flat_predictions = (np.array(flat_logits) >= 0.5).astype(np.int)\n",
        "flat_true_labels = true_labels\n",
        "\n",
        "    # Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_logits = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n",
        "flat_true_labels = np.asarray(true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7DFhB1Y2isx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, precision_recall_curve, \\\n",
        "    auc, matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def model_auc(y_true, y_pred):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "    return auc_score, fpr, tpr, thresholds\n",
        "\n",
        "def model_aupr(y_true, y_pred):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
        "    aupr_score = auc(recall, precision)\n",
        "    return aupr_score, precision, recall, thresholds\n",
        "\n",
        "def write_performance(flat_true_labels, flat_predictions, flat_logits, config):\n",
        "    test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "    test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "    test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "    test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "    test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n",
        "\n",
        "    test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "    test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)\n",
        "\n",
        "    test_msl = 128\n",
        "\n",
        "    test_seed = 42\n",
        "\n",
        "    test_time = time.ctime()\n",
        "\n",
        "    exp_path = \"{}_{}_{}.csv\".format(config.task_name, config.embed_mode, test_msl)\n",
        "\n",
        "    header = \"Len,Dir,Seed,Accuracy,F1_Score,Precision,Recall,AUC,MCC,AUPR,Time\"\n",
        "    content = \"{},{},{},{},{},{},{},{},{},{},{}\".format(test_msl,\n",
        "                                                        test_seed,\n",
        "                                                        test_accuracy,\n",
        "                                                        test_f1,\n",
        "                                                        test_prec,\n",
        "                                                        test_rec,\n",
        "                                                        test_auc,\n",
        "                                                        test_mc,\n",
        "                                                        test_aupr,\n",
        "                                                        test_time)\n",
        "\n",
        "    print(content)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n",
        "\n",
        "test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n",
        "\n",
        "test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)"
      ],
      "metadata": {
        "id": "4vX96GDISFUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3OHdRsN2XWI"
      },
      "outputs": [],
      "source": [
        "test_auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_f1"
      ],
      "metadata": {
        "id": "aaLNuBQMR1Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_rec"
      ],
      "metadata": {
        "id": "knlJ3StfNOyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_aupr"
      ],
      "metadata": {
        "id": "s2c4mdYCNTAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mc"
      ],
      "metadata": {
        "id": "_S6Haf0zNUnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy"
      ],
      "metadata": {
        "id": "gWO2dFmmNXmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Jpy434sNc-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPW7Mk7wsfyeE3mnbIaM1DZ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}